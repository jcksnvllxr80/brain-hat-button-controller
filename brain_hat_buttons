#!/usr/bin/python

import time
import yaml
import board
import requests
from digitalio import DigitalInOut, Direction, Pull
import subprocess
import os
import logging
from datetime import datetime

BUTTON_PIN = board.D17
JOYDOWN_PIN = board.D27
JOYLEFT_PIN = board.D22
JOYUP_PIN = board.D23
JOYRIGHT_PIN = board.D24
JOYSELECT_PIN = board.D16
HOME_DIR = '/home/pi/brain-hat-button-controller/'

mode = 'default'
camera_func = 'none'
camera_funcs = ['menu', 'capture', 'video', 'stopmotion']
buttons = [BUTTON_PIN, JOYUP_PIN, JOYDOWN_PIN,
           JOYLEFT_PIN, JOYRIGHT_PIN, JOYSELECT_PIN]
for i,pin in enumerate(buttons):
  buttons[i] = DigitalInOut(pin)
  buttons[i].direction = Direction.INPUT
  buttons[i].pull = Pull.UP
button, joyup, joydown, joyleft, joyright, joyselect = buttons
tf_obj_recognition_pid_str = "ps aux | grep -ivE \"(grep|venv)\" | grep pitft_labeled_output.py | awk \'{print $2}\'"
HOME_DIR = "/home/pi/brain-hat-button-controller/"
CONFIG_FILE = HOME_DIR + "conf/application.yaml"
pi_cam_app_settings = {}
subprocess.Popen(HOME_DIR + "pi_cam_app")

def init_logging():
  logging_logger = logging.getLogger(__name__)
  logging_logger.setLevel(logging.DEBUG)
  logging_logger.propagate = False
  # create console handler and set level to info
  handler = logging.StreamHandler()
  handler.setLevel(logging.DEBUG)
  formatter = logging.Formatter("%(asctime)s [brain_hat_buttons] [%(levelname)-5.5s]  %(message)s")
  handler.setFormatter(formatter)
  logging_logger.addHandler(handler)
  return logging_logger

def config():
  global pi_cam_app_settings
  config_file = read_config_file()
  # read config dict's into more specific variables
  pi_cam_app_settings = {k: v for k, v in config_file['pi_cam_app'].items()}

def read_config_file():
  # read config yaml file into dictionaries
  config_file = None
  with open(CONFIG_FILE, 'r') as ymlfile:
    config_file = yaml.full_load(ymlfile)
  return config_file

def change_mode(new_mode='default'):
  global mode
  mode = new_mode
  if mode == 'default':
    change_camera_func('none')
  logger.info("Mode changed to {0}".format(mode))

def change_camera_func(new_camera_func='capture'):
  global camera_func
  camera_func = new_camera_func
  logger.info("Camera function changed to {0}".format(camera_func))

def start_tf_obj_recognition():
  # NOTE: in order to get the speaker to work on the brainCraft hat, the following line
  # pipes the detected text into sudo festival in line 150 of the link below.
  # the reason the speaker stuff doesnt just work is that i am nott running the code as root.
  # https://github.com/adafruit/rpi-vision/blob/master/tests/pitft_labeled_output.py
  #######################################################################
  # os.system('echo %s | sudo festival --tts & ' % detecttext)  # this is the changed line
  #######################################################################
  if pi_cam_is_previewing():
    pi_cam_preview('stop')
    change_mode()
  os.environ["DISPLAY"] = ":0"
  subprocess.Popen("{0}tf_obj_recognition".format(HOME_DIR))

def video_recorder():
  # change_mode('video')
  # TODO: record movie (might need a new script for this that is very similar to pi_cam_app)
  # if already recording a video, then stop, else start recording
  pass

def stopmotion_animation():
  # change_mode('stopmotion')
  # TODO: make stop motion animation (might need a new script for this that is very similar to pi_cam_app)
  # if already making stopmotion animation, then stop, else start stopmotion animation
  pass

def pi_cam_preview(action):
  make_get_api_call("http://127.0.0.1:{0}/pi_cam_preview/{1}".format(pi_cam_app_settings['port'], action))

def pi_cam_is_previewing():
  api_call_str = "http://127.0.0.1:{0}/is_previewing".format(pi_cam_app_settings['port'])
  logger.info("Making a GET call to \'{0}\'".format(api_call_str))
  response = requests.get(api_call_str).content.decode("utf-8")
  logger.info("Camera is previewing: {0}".format(response))
  return True if response == 'True' else False

def photo():
  if camera_func in ["capture", 'menu']:
    logger.info("Taking photo")
    make_get_api_call("http://127.0.0.1:{0}/take_photo/{1}".format(pi_cam_app_settings['port'], create_new_unique_filename()))
  elif camera_func == 'stopmotion':
    logger.info("Adding stopmotion frame")
    # TODO: add frame to ~/stopmotion, when leaving stopmotion make video and clean up dir
  elif camera_func == 'video':
    logger.info("recording video")
    # TODO: take video and save in  ~/Videos
  else:
    pass_func()

def create_new_unique_filename():
  return "{0}".format(datetime.now().strftime("%Y%m%d_%H%M%S"))

def obj_recognition():
  kill_pid_or_start_func(tf_obj_recognition_pid_str, start_tf_obj_recognition)

def pi_cam_app():
  start_or_stop_pi_cam_preview()

def cam_mode_up():
  if camera_func == 'menu':
    next_menu_item('up')
  else:
    cam_zoom('in')

def cam_mode_down():
  if camera_func == 'menu':
    next_menu_item('down')
  else:
    cam_zoom('out')

def next_menu_item(dir):
  make_get_api_call("http://127.0.0.1:{0}/next_menu_item/{1}".format(pi_cam_app_settings['port'], dir))

def cam_zoom(dir):
  make_get_api_call("http://127.0.0.1:{0}/zoom/{1}".format(pi_cam_app_settings['port'], dir))

def left_value():
  next_value('left')

def right_value():
  next_value('right')

def next_value(dir):
  if camera_func == 'menu':
    make_get_api_call("http://127.0.0.1:{0}/next_value/{1}".format(pi_cam_app_settings['port'], dir))
  else:
    pass_func()

def left_cam_func():
  next_cam_function('left')

def right_cam_func():
  next_cam_function('right')

def next_cam_function(dir):
  current_cam_func_ind = camera_funcs.index(camera_func)
  if dir == 'left':
    if current_cam_func_ind == 0:
      next_cam_func = camera_funcs[len(camera_funcs) - 1]
    else:
      next_cam_func = camera_funcs[current_cam_func_ind - 1]
  else:
    if current_cam_func_ind == len(camera_funcs) - 1:
      next_cam_func = camera_funcs[0]
    else:
      next_cam_func = camera_funcs[current_cam_func_ind + 1]
  change_camera_func(next_cam_func)
  make_get_api_call("http://127.0.0.1:{0}/display_on_screen/Function/{1}".format(pi_cam_app_settings['port'], next_cam_func))

def make_get_api_call(api_call_str):
  logger.info("Making a GET call to \'{0}\'".format(api_call_str))
  response = requests.get(api_call_str)
  logger.info("Response from api call: {0}".format(response.content.decode("utf-8")))

def joystick_up_handler(was_long_press):
  if mode == 'camera':
    short_or_long_press_func(was_long_press, cam_mode_up, shutdown)
  else:
    short_or_long_press_func(was_long_press, pass_func, shutdown)

def joystick_down_handler(was_long_press):
  if mode == 'camera':
    short_or_long_press_func(was_long_press, cam_mode_down, pi_cam_app)
  else:
    short_or_long_press_func(was_long_press, pass_func, pi_cam_app)

def joystick_left_handler(was_long_press):
  if mode == 'camera':
    short_or_long_press_func(was_long_press, left_value, left_cam_func)
  else:
    short_or_long_press_func(was_long_press, pass_func, pass_func)

def joystick_right_handler(was_long_press):
  if mode == 'camera':
    short_or_long_press_func(was_long_press, right_value, right_cam_func)
  else:
    short_or_long_press_func(was_long_press, pass_func, pass_func)

def joystick_select_handler(was_long_press):
  short_or_long_press_func(was_long_press, pass_func, reboot)

def button_handler(was_long_press):
  if mode == 'camera':
    short_or_long_press_func(was_long_press, photo, obj_recognition)
  else:
    short_or_long_press_func(was_long_press, pass_func, obj_recognition)

def get_press_length(button, button_name):
  long_pressed = 0
  t_start = datetime.now()
  while not button.value:
    time.sleep(0.01)
  t_end = datetime.now()
  if (t_end - t_start).seconds < 1:
    logger.info(button_name + " pressed")
  else:
    logger.info(button_name + " long-pressed")
    long_pressed = 1
  return long_pressed

def button_check():
  if not button.value:
    button_handler(get_press_length(button, "Button"))
  if not joyup.value:
    joystick_up_handler(get_press_length(joyup, "Joystick up"))
  if not joydown.value:
    joystick_down_handler(get_press_length(joydown, "Joystick down"))
  if not joyleft.value:
    joystick_left_handler(get_press_length(joyleft, "Joystick left"))
  if not joyright.value:
    joystick_right_handler(get_press_length(joyright, "Joystick right"))
  if not joyselect.value:
    joystick_select_handler(get_press_length(joyselect, "Joystick select"))

def get_pid(get_pid_cmd_str):
  return subprocess.check_output([get_pid_cmd_str], shell=True).decode().rstrip()

def kill_pid(pid):
  os.system("kill -9 " + str(pid))

def kill_pid_or_start_func(get_pid_str, func):
  pid = get_pid(get_pid_str)
  if pid:
    kill_pid(pid)
    change_mode()
  else:
    func()

def start_or_stop_pi_cam_preview():
  if pi_cam_is_previewing():
    pi_cam_preview('stop')
    change_mode()
  else:
    pid = get_pid(tf_obj_recognition_pid_str)
    if pid:
      kill_pid(pid)
    change_mode('camera')
    change_camera_func()
    pi_cam_preview('start')

def short_or_long_press_func(was_long_press, short_func, long_func):
  if was_long_press:
    logger.debug("Running long function, {0}".format(long_func))
    long_func()
  else:
    logger.debug("Running short function, {0}".format(short_func))
    short_func()
  time.sleep(0.35)

def reboot():
  os.system("sudo reboot now")

def shutdown():
  os.system("sudo shutdown -h now")

def pass_func():
  logger.warning("This function has not been implemented for mode: \'{0}\',  camera function: \'{1}\'".format(mode, camera_func))

if __name__ == '__main__':
  global logger
  logger = init_logging()
  config()
  while True:
    button_check()
    time.sleep(0.01)

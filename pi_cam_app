#!/usr/bin/python

''' TODO:
- video
- stopmotion
- when a thread starts, kill the last thread
- open a browser when to the locally streamed video when in camera mode or find another wya to display it.
  maybe find out how the tf gets it to the display
'''

import time
import os
import sys
import yaml
import logging
from ast import literal_eval
from traceback import format_exception
from threading import Thread
from picamera import PiCamera
from picamera.color import Color
from flask_cors import CORS
from flask import request, jsonify, Flask # package for the webapp

camera = PiCamera()
app = Flask(__name__)
menu_items = ['photo_effect' , 'resolution', 'awb_mode', 'exposure_mode', 'capture_format', 'annotate_background', 
  'speaker_volume', 'meter_mode', 'horizontal_flip', 'vertical_flip', 'iso', 'rotation', 'saturation', 'sharpness', 
  'shutter_speed', 'video_denoise', 'video_stabilization', 'zoom_speech', 'menu_speech', 'value_speech']
photo_effects = [ 'none', 'negative', 'solarize', 'sketch', 'denoise', 'emboss', 'oilpaint', 'hatch', 'gpen', 'pastel', 
  'watercolor', 'film', 'blur', 'saturation', 'colorswap', 'washedout', 'posterise', 'colorpoint', 
  'colorbalance', 'cartoon', 'deinterlace1', 'deinterlace2' ]
resolutions = [(2028, 1080), (2028, 1520), (4056, 3040), (1332, 990)]
awb_modes = ['off', 'auto', 'sunlight', 'cloudy', 'shade', 'tungsten', 'fluorescent', 'incandescent', 'flash', 'horizon']
exposure_modes = ['off', 'auto', 'night', 'nightpreview', 'backlight', 'spotlight', 'sports', 'snow', 'beach', 
  'verylong', 'fixedfps', 'antishake', 'fireworks']
capture_formats = ['jpeg', 'png', 'gif', 'bmp', 'yuv', 'rgb', 'rgba', 'bgr', 'bgra', 'raw']
annotate_background_colors = ['aliceblue', 'antiquewhite', 'aqua', 'antiquewhite', 'aqua', 'aquamarine', 'azure', 'beige',
  'bisque', 'black', 'blanchedalmond', 'blue', 'blueviolet', 'brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate',
  'coral', 'cornflowerblue', 'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen',
  'darkgrey', 'darkkhaki', 'darkmagenta', 'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darksalmon', 'darkseagreen',
  'darkslateblue', 'darkslategray', 'darkslategrey', 'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue', 'dimgray',
  'dimgrey', 'dodgerblue', 'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', 'gainsboro', 'ghostwhite', 'gold', 'goldenrod',
  'gray', 'green', 'greenyellow', 'grey', 'honeydew', 'hotpink', 'indianred', 'indigo', 'ivory', 'khaki', 'lavender',
  'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', 'lightcoral', 'lightcyan', 'lightgoldenrodyellow', 'lightgray',
  'lightgreen', 'lightgrey', 'lightpink', 'lightsalmon', 'lightseagreen', 'lightskyblue', 'lightslategray', 'lightslategrey',
  'lightsteelblue', 'lightyellow', 'lime', 'limegreen', 'linen', 'magenta', 'maroon', 'mediumaquamarine', 'mediumblue',
  'mediumorchid', 'mediumpurple', 'mediumseagreen', 'mediumslateblue', 'mediumspringgreen', 'mediumturquoise', 'mediumvioletred',
  'midnightblue', 'mintcream', 'mistyrose', 'moccasin', 'navajowhite', 'navy', 'oldlace', 'olive', 'olivedrab', 'orange',
  'orangered', 'orchid', 'palegoldenrod', 'palegreen', 'paleturquoise', 'palevioletred', 'papayawhip', 'peachpuff', 'peru',
  'pink', 'plum', 'powderblue', 'purple', 'red', 'rosybrown', 'royalblue', 'saddlebrown', 'salmon', 'sandybrown', 'seagreen',
  'seashell', 'sienna', 'silver', 'skyblue', 'slateblue', 'slategray', 'slategrey', 'snow', 'springgreen', 'steelblue', 'tan',
  'teal', 'thistle', 'tomato', 'turquoise', 'violet', 'wheat', 'white', 'whitesmoke', 'yellow', 'yellowgreen']
speaker_volumes = [0, 20, 40, 60, 80, 100]  # vol = x/4 + 75
meter_modes = ['average', 'spot', 'backlit', 'matrix']
horizontal_flip_options = [True, False]
vertical_flip_options = [True, False]
iso_values = [0, 100, 200, 320, 400, 500, 640, 800]  # zero auto
rotation_angles = [0, 90, 180, 270]
saturation_range = list(range(-100, 101 ,5))  # default=0
sharpness_range = list(range(-100, 101 ,5))
shutter_speed_range = [0]  # zero auto; TODO: find out the range of this attribute
video_denoise_options = [True, False]  # default=True
video_stabilization_options = [True, False]  # default=False
zoom_range = list(range(0, 100 ,5)) 
zoom_speech_options = [True, False]
menu_speech_options = [True, False]
value_speech_options = [True, False]

HOME_DIR = "/home/pi/"
IMAGES_DIR = HOME_DIR + "Pictures/"
VIDEO_DIR = HOME_DIR + "Videos/"
STOPMOTION_DIR = HOME_DIR + "stopmotion/"
APP_DIR = HOME_DIR + "brain-hat-button-controller/"
CONFIG_FILE = APP_DIR + "conf/application.yaml"
pi_cam_app_settings = {}
current_menu_item = menu_items[0]

def init_logging():
  logging_logger = logging.getLogger(__name__)
  logging_logger.setLevel(logging.DEBUG)
  logging_logger.propagate = False
  # create console handler and set level to info
  handler = logging.StreamHandler()
  handler.setLevel(logging.DEBUG)
  formatter = logging.Formatter("%(asctime)s [pi_cam_app] [%(levelname)-5.5s]  %(message)s")
  handler.setFormatter(formatter)
  logging_logger.addHandler(handler)
  return logging_logger

def setup():
  global current_menu_values
  global menu_items_dict
  global menu_functions
  global pi_cam_app_settings
  global zoom_index
  zoom_index = 0
  menu_items_dict = {
    'photo_effect': photo_effects,
    'resolution': resolutions,
    'awb_mode': awb_modes,
    'exposure_mode': exposure_modes,
    'capture_format': capture_formats,
    'annotate_background': annotate_background_colors,
    'speaker_volume': speaker_volumes,
    'meter_mode': meter_modes,
    'horizontal_flip': horizontal_flip_options,
    'vertical_flip': vertical_flip_options,
    'iso': iso_values,
    'rotation': rotation_angles,
    'saturation': saturation_range,
    'sharpness': sharpness_range,
    'shutter_speed': shutter_speed_range,
    'video_denoise': video_denoise_options,
    'video_stabilization': video_stabilization_options,
    'zoom_speech': zoom_speech_options,
    'menu_speech': menu_speech_options,
    'value_speech': value_speech_options
  }
  menu_functions = {
    'photo_effect': set_photo_effect,
    'resolution': set_menu_resolution,
    'awb_mode': set_awb_mode,
    'exposure_mode': set_exposure_mode,
    'capture_format': set_capture_format,
    'annotate_background': set_annotate_background,
    'speaker_volume': set_speaker_volume,
    'meter_mode': set_meter_mode,
    'horizontal_flip': set_horizontal_flip,
    'vertical_flip': set_vertical_flip,
    'iso': set_iso,
    'rotation': set_rotation,
    'saturation': set_saturation,
    'sharpness': set_sharpness,
    'shutter_speed': set_shutter_speed,
    'video_denoise': set_video_denoise,
    'video_stabilization': set_video_stabilization,
    'zoom_speech': set_zoom_speech,
    'menu_speech': set_menu_speech,
    'value_speech': set_value_speech
  }
  config_file = read_config_file()
  # read config dict's into more specific variables
  pi_cam_app_settings = {k: v for k, v in config_file['pi_cam_app'].items()}
  camera_settings = {k: v for k, v in config_file['camera'].items()}
  current_menu_values = {
    'photo_effect': camera_settings['photo_effect'],
    'resolution': literal_eval(camera_settings['resolution']),
    'awb_mode': camera_settings['awb_mode'],
    'exposure_mode': camera_settings['exposure_mode'],
    'capture_format': camera_settings['capture_format'],
    'annotate_background': camera_settings['annotate_background'],
    'speaker_volume': camera_settings['speaker_volume'],
    'meter_mode': camera_settings['meter_mode'],
    'horizontal_flip': camera_settings['horizontal_flip'],
    'vertical_flip': camera_settings['vertical_flip'],
    'iso': camera_settings['iso'],
    'rotation': camera_settings['rotation'],
    'saturation': camera_settings['saturation'],
    'sharpness': camera_settings['sharpness'],
    'shutter_speed': camera_settings['shutter_speed'],
    'video_denoise': camera_settings['video_denoise'],
    'video_stabilization': camera_settings['video_stabilization'],
    'zoom_speech': camera_settings['zoom_speech'], 
    'menu_speech': camera_settings['menu_speech'], 
    'value_speech': camera_settings['value_speech']
  }
  logger.debug("{0}".format(current_menu_values))

def init_web_app():
  web_app_ip = pi_cam_app_settings['ip']
  web_app_port = pi_cam_app_settings['port']
  CORS(app)
  app.config["DEBUG"] = True
  logger.info("Starting pi_cam_app on ip:port --> " + web_app_ip + ':' + str(web_app_port))
  app.run(host=web_app_ip, port=int(web_app_port), use_reloader=False)

def read_config_file():
  # read config yaml file into dictionaries
  config = None
  with open(CONFIG_FILE, 'r') as ymlfile:
    config = yaml.full_load(ymlfile)
  return config

def write_config_file(data):
  with open(CONFIG_FILE, 'w') as ymlfile:
    yaml.dump(data, ymlfile)

def write_value_to_config_file(new_val):
  config = read_config_file()
  if current_menu_item is 'resolution':
    new_val = str(new_val)
  config['camera'][current_menu_item] = new_val
  write_config_file(config)

@app.route('/')
def hello():
  return 'Hello, from pi_cam_app!'

@app.route('/pi_cam_preview/<action>', methods=['GET'])
def pi_cam_preview_request(action):
  return handle_pi_cam_preview_request(action)

@app.route('/is_previewing', methods=['GET'])
def is_previewing_request():
  return handle_is_previewing_request()

@app.route('/take_photo/<filename>', methods=['GET'])
def take_photo_request(filename):
  message = handle_take_photo_request(filename)
  logger.info(message)
  return message

@app.route('/next_menu_item/<direction>', methods=['GET'])
def next_menu_item(direction):
  message = handle_next_menu_item_request(direction)
  return message

@app.route('/next_value/<direction>', methods=['GET'])
def next_value(direction):
  message = handle_next_value_request(direction)
  return message

@app.route('/zoom/<direction>', methods=['GET'])
def zoom(direction):
  message = handle_zoom(direction)
  return message

@app.route('/display_and_speak/<key>/<value>', methods=['GET'])
def display_and_speak(key, value):
  Thread(target=set_image_text, args=('set_image_text', 3, key, value, True)).start()
  return "Message displayed with text {0}: {1}".format(key, value)

@app.route('/help', methods=['GET'])
def help_request():
  message = "This is the help message."
  logger.info(message)
  return jsonify(display_message=message)

@app.errorhandler(404)
def page_not_found(e):
  logger.error("404: The resource could not be found.")
  return jsonify(display_message="Error.")

def handle_is_previewing_request():
  preview = camera.previewing
  message = "Camera in preview: {0}".format(preview)
  logger.info(message)
  return str(preview)

def handle_pi_cam_preview_request(action):
  global camera
  if action == "start":
    if camera.closed:
      camera = PiCamera()
    load_camera_settings_with_config()
    camera.start_preview()
    camera.preview_fullscreen = True
    display_and_speak('Mode', 'camera')
    msg = "Started pi cam preview."
  else:
    camera.stop_preview()
    camera.close()
    msg = "Stopped and closed pi cam preview."
  logger.info(msg)
  return msg

def load_camera_settings_with_config():
  for menu_item in menu_items:
    menu_functions[menu_item](current_menu_values[menu_item])

def handle_take_photo_request(filename):
  filepath = "{0}{1}.{2}".format(IMAGES_DIR, filename, capture_format)
  try:
    shoot(filepath)
    message = "{0} written successfully!".format(filepath)
  except:
    exc_type, exc_value, exc_tb = sys.exc_info()
    exception_handler(exc_type, exc_value, exc_tb)
    message = "{0} not successfully written!".format(filepath)
  return message

def shoot(filepath):
  camera.capture(filepath, format=capture_format)

def set_resolution(x, y, fps=None):
  camera.resolution = (x, y)
  if fps:
    camera.framerate = fps

def handle_next_menu_item_request(direction):
  if direction in ['up', 'down']:
    msg = go_to_next_menu_item(direction)
  else:
    msg = "No action taken for invalid direction: " + direction
    logger.warning(msg)
  return msg

def handle_next_value_request(direction):
  if direction in ['left', 'right']:
    msg = go_to_next_value(direction)
  else:
    msg = "No action taken for invalid direction: " + direction
    logger.warning(msg)
  return msg

def handle_zoom(direction):
  if direction in ['in', 'out']:
    msg = do_zoom(direction)
  else:
    msg = "No action taken for invalid direction: " + direction
    logger.warning(msg)
  return msg

def go_to_next_menu_item(dir):
  global current_menu_item
  current_menu_item_ind = menu_items.index(current_menu_item)
  if dir == 'down':
    if current_menu_item_ind == 0:
      next_menu_item = menu_items[len(menu_items) - 1]
    else:
      next_menu_item = menu_items[current_menu_item_ind - 1]
  else:
    if current_menu_item_ind == len(menu_items) - 1:
      next_menu_item = menu_items[0]
    else:
      next_menu_item = menu_items[current_menu_item_ind + 1]
  current_menu_item = next_menu_item
  display_str = "{0} = {1}".format(current_menu_item.replace("_", " "), current_menu_values[current_menu_item])
  Thread(target=set_image_text, args=('set_image_text', 3, 'Menu', display_str, current_menu_values['menu_speech'])).start()
  msg = "Changed menu item {0} one to \'{1}\'".format(dir, next_menu_item)
  logger.info(msg)
  return msg

def go_to_next_value(dir):
  global current_menu_values
  current_menu_item_list = menu_items_dict[current_menu_item]
  current_value_ind = current_menu_item_list.index(current_menu_values[current_menu_item])
  if dir == 'left':
    if current_value_ind == 0:
      next_value = current_menu_item_list[len(current_menu_item_list) - 1]
    else:
      next_value = current_menu_item_list[current_value_ind - 1]
  else:
    if current_value_ind == len(current_menu_item_list) - 1:
      next_value = current_menu_item_list[0]
    else:
      next_value = current_menu_item_list[current_value_ind + 1]
  current_menu_values[current_menu_item] = next_value
  display_text = menu_functions[current_menu_item](next_value)
  Thread(target=set_image_text, args=('set_image_text', 3, display_text, next_value, current_menu_values['value_speech'])).start()
  write_value_to_config_file(current_menu_values[current_menu_item])
  msg = "Changed value one to the {0}, \'{1}\'".format(dir, next_value)
  logger.info(msg)
  return msg

def do_zoom(dir):
  '''
  zoom = (x, y, w, h) tuple of floating point values ranging from 0.0 to 1.0, 
  indicating the proportion of the image to include in the output 
  (this is also known as the “Region of Interest” or ROI). The default value is (0.0, 0.0, 1.0, 1.0)
  '''
  global zoom_index
  msg = "Fully zoomed {0}!".format(dir)
  if dir == 'out':
    if zoom_index > 0:
      zoom_index -= 1
      msg = calculate_and_set_zoom()
  else:
    if zoom_index < len(zoom_range) - 1:
      zoom_index += 1
      msg = calculate_and_set_zoom()
  logger.info(msg)
  return msg

def calculate_and_set_zoom():
  zoom_tuple = calculate_zoom(zoom_index)
  display_text = set_zoom(*zoom_tuple)
  Thread(target=set_image_text, args=('set_image_text', 3, display_text, str(zoom_tuple), current_menu_values['zoom_speech'])).start()
  return "Zoomed {0} to, {1}%".format(dir, zoom_index * 5)

def calculate_zoom(zoom_i):
  x_y = round(zoom_i / (2 * len(zoom_range)), 3)
  w_h = round(1 - 2 * x_y, 3)
  return (x_y, x_y, w_h, w_h)

def set_photo_effect(effect):
  camera.image_effect = effect
  logger.info("Set photo effect to \'{0}\'".format(effect))
  return 'Effect'

def set_menu_resolution(resolution):
  set_resolution(*resolution)  # resolution is a tuple so gather and spit out its values
  logger.info("Set resolution to \'{0}\'".format(resolution))
  return 'Resolution'

def set_awb_mode(auto_white_balance_mode):
  camera.awb_mode = auto_white_balance_mode
  logger.info("Set AWB mode to \'{0}\'".format(auto_white_balance_mode))
  return 'AWB Mode'

def set_exposure_mode(exposure_mode):
  camera.exposure_mode = exposure_mode
  logger.info("Set exposure mode to \'{0}\'".format(exposure_mode))
  return 'Exposure'

def set_capture_format(format):
  global capture_format
  capture_format = format
  logger.info("Set capture format to \'{0}\'".format(format))
  return 'Capture Format'

def set_annotate_background(color):
  camera.annotate_background = Color(color)
  logger.info("Set annotation background color to \'{0}\'".format(color))
  return 'Annotate Background'

def set_speaker_volume(vol):
  speaker_percentage = (vol / 4) + 75 if vol else 0
  os.system("amixer sset -c 2 \'Speaker\',0 {0}%".format(speaker_percentage))
  logger.info("Set speaker volume to \'{0}\' which translates to {1}%".format(vol, speaker_percentage))
  return "Speaker Volume"

def set_meter_mode(mode):
  camera.meter_mode = mode
  logger.info("Set meter mode to \'{0}\'".format(mode))
  return 'Meter Mode'

def set_horizontal_flip(h_flip):
  camera.hflip = h_flip
  logger.info("Set horizontal flip to \'{0}\'".format(h_flip))
  return 'Horizontal Flip'

def set_vertical_flip(v_flip):
  camera.vflip = v_flip
  logger.info("Set vertical flip to \'{0}\'".format(v_flip))
  return 'Vertical Flip'

def set_iso(iso):
  camera.iso = iso
  logger.info("Set ISO to \'{0}\'".format(iso))
  return 'ISO'

def set_rotation(rotation):
  camera.rotation = rotation
  logger.info("Set rotation to \'{0}\'".format(rotation))
  return 'Rotation'

def set_saturation(saturation):
  camera.saturation = saturation
  logger.info("Set saturation to \'{0}\'".format(saturation))
  return 'Saturation'

def set_sharpness(sharpness):
  camera.sharpness = sharpness
  logger.info("Set sharpness to \'{0}\'".format(sharpness))
  return 'Sharpness'

def set_shutter_speed(shutter_speed):
  camera.shutter_speed = shutter_speed
  logger.info("Set shutter speed to \'{0}\'".format(shutter_speed))
  return 'Shutter Speed'

def set_video_denoise(video_denoise):
  camera.video_denoise = video_denoise
  logger.info("Set video denoise to \'{0}\'".format(video_denoise))
  return 'Video Denoise'

def set_video_stabilization(video_stabilization):
  camera.video_stabilization = video_stabilization
  logger.info("Set video stabilization to \'{0}\'".format(video_stabilization))
  return 'Video Stabilization'

def set_zoom(x, y, w, h):
  camera.zoom = (x, y, w, h)
  return 'Zoom'

def set_zoom_speech(speak_zoom_params):
  current_menu_values['zoom_speech'] = speak_zoom_params
  logger.info("Set zoom speech to \'{0}\'".format(speak_zoom_params))
  return 'Zoom Speech'

def set_menu_speech(speak_menu_params):
  current_menu_values['menu_speech'] = speak_menu_params
  logger.info("Set menu speech to \'{0}\'".format(speak_menu_params))
  return 'Menu Speech'

def set_value_speech(speak_value_params):
  current_menu_values['value_speech'] = speak_value_params
  logger.info("Set value speech to \'{0}\'".format(speak_value_params))
  return 'Value Speech'

def set_image_text(thread_name, wait_seconds, display_str, value_name, speak=None):
  logger.info("Thread \'{0}\': starting".format(thread_name))
  logger.debug("Resolution: {0}".format(current_menu_values['resolution']))
  desired_res = int(0.07 * min(current_menu_values['resolution']))
  camera.annotate_text_size = desired_res if desired_res < 160 else 160
  camera.annotate_text = "{0}: {1}".format(display_str, value_name)
  if speak:
    os.system("echo \"{1}\" | sudo festival --tts & ".format(display_str, value_name))
  time.sleep(wait_seconds)
  camera.annotate_text = ''
  logger.info("Thread \'{0}\': finishing".format(thread_name))

def exception_handler(exc_type, exc_value, exc_tb):
  err_str = str(format_exception(exc_type, exc_value, exc_tb))
  error_log = "An exception was encountered: " + err_str
  logger.error(error_log)

if __name__ == '__main__':
  global logger
  logger = init_logging()
  setup()
  init_web_app()
  while True:
    time.sleep(0.01)
